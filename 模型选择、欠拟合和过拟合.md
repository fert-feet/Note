# 模型选择、欠拟合和过拟合

## 训练误差和泛化误差

- 训练误差：模型在训练数据上的误差。
- 泛化误差：模型在新数据上的误差（更关心泛化误差）

例如这一场考试考了高分，不代表未来考试（一定）会好。

## 验证数据集和测试数据集

- 验证数据集：用来评估已训练模型的好坏，比如拿出百分之50的训练数据作为验证数据集，是不参与训练的，一般用来评估超参数的好坏并选择超参数。
- 测试数据集：只能用一次的数据集，实际上就是应用于实际的数据，再测一次没有任何意义，甚至连标号都不知道

验证数据集相当于平时的模拟考试，而测试数据集相当于高考。

## K-则交叉验证

k 则交叉验证（k-fold cross-validation）是一种常用的模型评估方法，用于评估机器学习模型的性能和泛化能力，步骤如下：

- 将训练数据分割成 K 块（折）。
- 对于每一折，将第i折作为验证集，其余k-1折作为训练集去训练 `num_epochs` 次模型（训练都是独立的，不会记忆上一轮的训练）。
- 一共进行 K 轮训练，并记录下每次训练的各种指标，如准确率，精确率，误差等。
- 将k次验证结果的平均值作为模型的性能指标。

k 则交叉验证不仅可以用于评估模型性能，也可以：

1. 对 K 次训练的误差排序，并选出误差最小的一次训练作为最佳模型使用（模型选择），由于每个训练数据集都过了一遍，有效防止过拟合和并更好的泛化未见过的数据
2. 在 K 次迭代中不断调整超参数的值（超参数调优），并选择最优超参数。

常用的 K 有 5 或 10

## 过拟合和欠拟合

- 过拟合就是在训练数据集上表现的好，在测试数据集（新数据）表现不好，原因有以下：

  - 模型复杂度过高：如使用了过多的参数或过复杂的算法

  - 训练数据不足：数据量不足导致模型容易记住每个训练样本的特征（在测试新数据的时候应该用模型对训练数据趋势的理解去判断新数据，但过拟合记住了所有数据，导致拟合曲线不匹配，下面会提到）

  - 数据噪声：模型学习到了训练数据中的噪声和异常值

- 欠拟合是指模型在训练数据上和新数据上都表现较差，无法捕捉到数据中的重要模式和趋势，原因如下：

  - 模型复杂度过低：如使用了过于简单的模型或过少的参数
  - 数据不足：输入特征没有包含足够的信息来预测输出

  - 训练不足：模型没有充分训练，未能从数据中学习到有效的模式

#### 模型容量

模型容量指一个模型拟合各种函数的能力，当模型越复杂往往代表模型容量越高，低容量的模型难以拟合训练数据，高容量的模型可以记住所有训练数据，如下图所示，低容量不多说，高容量的模型记住了所有的训练数据而非趋势（**真实的曲线应该是像二次曲线般光滑**，偏离光滑曲线的部分是噪声）

<img src="https://s2.loli.net/2024/05/29/BxfdkASnTgoePCV.png" alt="image-20240529160137131" style="zoom:67%;" />

### 模型容量的影响

调参的思路，一般是从欠拟合一直调到过拟合再在一个小区间里调，从图里可以看到，最优的区间是在泛化误差合训练误差较小，且两个误差的值也相对较小的时候为最优，一般先控制模型容量到一个较大的位置，然后再让两个误差的值较接近。

实际上也就是先将模型拉到过拟合，再调整两个误差使其相近，最后到达一个较优的位置。

<img src="https://s2.loli.net/2024/05/29/b5U3O9vQoJdIj4R.png" alt="image-20240529160421209" style="zoom:67%;" />

### 估计模型容量

- 我们难以再不同种类的算法（模型）之间比较，例如树模型合神经网络，我们就没法比较两个模型容量大小
- 给定一个模型种类，将有两个因素可以评估模型容量
  - 参数的个数（越多模型容量越大）
  - 参数值的选择范围（越大模型容量也就越大）

### VC 维理论

对于一个分类模型，VC 等于一个最大的数据集（模型能够记住的最大数据）的大小，不管如何给定标号，都存在一个模型对它进行完美分类。

- 对于 2 维输入的感知机，VC 维 = 3（能够分类任意 3 个点，4 个不行-XOR）
- 支持 N 维输入的感知机的 VC 维是 N + 1
- 一些多层感知机的 VC 维是 $O(Nlog_2N)$

VC 维提供衡量训练误差合泛化误差之间间隔的理论依据，但深度学习中很少使用，主要是因为：

- 衡量不是很准
- 计算深度学习模型的 VC 维很困难 
